<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="">
    <meta name="author" content="cordinc">
    <title>Can Tweety fly?</title>
    <link href="/assets/css/bootstrap.css" rel="stylesheet">
    <link href="/assets/css/cordinc.css" rel="stylesheet">
    <link href="/assets/css/pygments/default.css" rel="stylesheet">
  </head>

  <body>

    <div class="navbar navbar-inverse navbar-fixed-top">
      <div class="container">
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="/">Cordinc</a>
        <div class="nav-collapse collapse">
          <ul class="nav navbar-nav">
            <li class=""><a href="/about.html">About</a></li>
            <li class=""><a href="/projects">Projects</a></li>
          </ul>
        </div><!--/.nav-collapse -->
      </div>
    </div>

    <div class="container">

       <div class="cordinc-content">
            <div class="row">
<div class="col-lg-8">
<b>July  3, 2011</b>
<h4>Can Tweety fly?</h4>
Tags: 
    
      <a class="post" href="/blog/tag/Memories.html">Memories</a>, 
    
      <a class="post" href="/blog/tag/University.html">University</a>
    
<br/><br/>
<p>The worst question you can ask a PhD student is “tell me about your
thesis”. Or at least, that was the joke among the postgrad students at
the <a href="http://web.csse.uwa.edu.au/">UWA CS department</a> in the mid 1990’s.
I took this seriously and prepared an explanation of my thesis that I
thought most people could understand (assuming some small knowledge of
logic). I only ever used this explanation once many years ago (at a job
interview for Rio Tinto R&amp;TD). So it is about time I explained it again
before I forget it all. For reference I did not complete my PhD,
dropping out after 18 months.</p>

<p>The provisional title of my thesis was “Using Nonmonotonic Logic to
extend Inductive Logic Programming”, and the research proposal is
<a href="/assets/posts/uni/phd_proposal.pdf">here</a>. The idea was to have
computers learn logical rules in a more natural manner than the existing
systems. First some background on each of the two terms in the title.</p>

<p><a href="http://en.wikipedia.org/wiki/First-order_logic">First-order Logic</a> is
what most people mean when talking about logic. It involves formulas
like <code class="language-plaintext highlighter-rouge">flies(X) &lt;- bird(X)</code> (all birds fly), which if you also have
<code class="language-plaintext highlighter-rouge">bird(Tweety)</code> (Tweety is a bird) implies <code class="language-plaintext highlighter-rouge">flies(Tweety)</code> (Tweety can
fly). One issue with First-order Logic is that it assumes perfect
knowledge. That is, it assumes that everything is known and correct.
Thus it is monotonic - it is not possible for any future information to
invalidate any previous implications. It can’t handle the situation
where in addition to the knowledge above, we later learn that Tweety is
a penguin and that penguins don’t fly. This new information invalidates
our old implication that Tweety flys and is not allowed. Instead you
have to know from that start that birds fly unless they are penguins.
However, Ostriches don’t fly, nor do dead birds or birds with broken
wings. With a little bit of thought many more exceptions to the rule
“birds fly” can be imagined, and the rule becomes unwieldly.</p>

<p>In real-world problems there can be many exceptions or inconsistent data
(noise), so First-order Logic can be problematic for machine learning.
There are ways around this though. Often it is used in self-contained
well-understood domain with few exceptions. However, many systems
instead use <a href="http://en.wikipedia.org/wiki/Non-monotonic_logic">Non-monotonic
Logic</a>, which allows
new knowledge to contradict old beliefs. Many Non-monotonic Logic
constructs seem so intuitive it is hard to imagine thinking without
them. The <a href="http://en.wikipedia.org/wiki/Closed_world_assumption">Closed-world Assumption
(CWA)</a> says that
if something is not known it must be false. When reading a train
timetable with a train at 8am and the next specified train at 9am, you
are using the CWA when you assume there is no train at 8:20am. Similar
is <a href="http://en.wikipedia.org/wiki/Negation_as_failure">Negation As Failure
(NAF)</a> (indeed it has
been proven they are logically the same) where if something can’t be
proven true then it must be false - sounds like a few university
researchers I knew. If you have used
<a href="http://en.wikipedia.org/wiki/Prolog">Prolog</a>, then you should be
familiar with NAF. The logic I was mainly working on was <a href="http://en.wikipedia.org/wiki/Default_logic">Default
Logic</a>, which allows rules
to be true by default assuming there is some justification. This allows
exceptions in a compact and natural rule system.</p>

<p>Given the rules resulting from the learning system would be in a
Non-monotonic Logic, the next step is to describe how those rules are
learnt. The example above where it was implied that Tweety could fly is
an example of <a href="http://en.wikipedia.org/wiki/Deductive_reasoning">Deductive
Reasoning</a>. Deduction
is the process of using some rules and some background facts to imply
new facts. <a href="http://en.wikipedia.org/wiki/Inductive_reasoning">Inductive
Reasoning</a> is the
reverse, deriving rules from facts. So if you know Tweety is a bird and
that Tweety flies, then you might derive the rule that all birds fly.
<a href="http://en.wikipedia.org/wiki/Inductive_logic_programming">Inductive Logic Programming
(ILP)</a> is just
the term for computer programs that perform this process with the
resulting rules as logic system. They take a set of background knowledge
and sets of positive and negative examples and try to create rules that
cover as many of the positive examples as possible while covering as few
of the negative examples as possible. This is a computationally
expensive process, computers only got powerful enough to do this for
non-trivial datasets in the late 80’s, so when I studied in the mid 90’s
the field was just getting started and becoming known.</p>

<p>My thesis attempted to marry the two concepts. There had been a few
attempts at this before, but the best known ILP systems at the time
didn’t handle exceptions or noise very well. Thus part 1 of my work was
to construct an ILP learning system that output a Non-monotonic logic.
This was about as far as I got, implementing some theoretical results
from another researcher (with minor improvements). Part 2 was handling
exceptions and noise better by flipping rules. That is, if the evidence
against a rule became too strong the system should flip it to the
reverse rule. I also looked at weakening the “strength” of a rule over
time. All rules have the same applicability in non-probalistic logics.
By “strength” I mean how long I keep a rule in my output theory before
modifying or flipping it in the presence of negative examples, or even
ignoring exceptions/noise if the rule is particularly “strong”. I didn’t
come up with anything meaningful here, I just thought it might be
useful. Although I have been told this became a hot research topic in
the years after I quit (under the term “forgetting”, I think).</p>

<p>This may sound like it was mainly a coding project, maybe because that
was where my interests lie. Most of my time should have been spent doing
maths to prove my work was correct as it was a very theoretical field.</p>

</div>

<div class="col-lg-2">
<br/>

<small>
<a href="/blog/archives.html">Full Archives</a>

<br/><br/>

Recent Posts:
<ul class="list-unstyled">
  
  <li>  
    <a href="/blog/2025/02/link-blog.html">Link Blog</a> 
  </li>  
  
  <li>  
    <a href="/blog/2025/01/goals.html">Goals 2024</a> 
  </li>  
  
  <li>  
    <a href="/blog/2025/01/boardgames.html">Boardgames of 2024</a> 
  </li>  
  
  <li>  
    <a href="/blog/2024/12/eoy-games.html">End of Year Games</a> 
  </li>  
  
  <li>  
    <a href="/blog/2024/11/netflix-games.html">Netflix Games</a> 
  </li>  
  
  <li>  
    <a href="/blog/2024/11/intelligence.html">Intelligence?</a> 
  </li>  
  
  <li>  
    <a href="/blog/2024/09/back-to-games.html">Back to Games</a> 
  </li>  
  
  <li>  
    <a href="/blog/2024/08/malaysia.html">Malaysia (again)</a> 
  </li>  
  
  <li>  
    <a href="/blog/2024/05/bad_companies.html">Bad Companies</a> 
  </li>  
  
  <li>  
    <a href="/blog/2024/03/media.html">Media Bias</a> 
  </li>  

</ul>

<br/><br/>

Top Tags: <ul class="list-unstyled"><li><a href="/blog/tag/Games.html">Games</a></li> <li><a href="/blog/tag/Technical.html">Technical</a></li> <li><a href="/blog/tag/A%20Gamedev%20Plays.html">A Gamedev Plays</a></li> <li><a href="/blog/tag/Travel.html">Travel</a></li> <li><a href="/blog/tag/History.html">History</a></li> <li><a href="/blog/tag/General.html">General</a></li> <li><a href="/blog/tag/Podcasts.html">Podcasts</a></li> <li><a href="/blog/tag/Memories.html">Memories</a></li> <li><a href="/blog/tag/Video%20Games.html">Video Games</a></li> <li><a href="/blog/tag/Finance.html">Finance</a></li> <li><a href="/blog/tag/Projects.html">Projects</a></li> <li><a href="/blog/tag/Meta.html">Meta</a></li> <li><a href="/blog/tag/Malaysia.html">Malaysia</a></li> <li><a href="/blog/tag/Goals.html">Goals</a></li> <li><a href="/blog/tag/Java.html">Java</a></li></ul>

</small>
</div>

<div class="col-lg-2">
</div>
</div>

       </div>

    </div><!-- /.container -->

  </body>
</html>
